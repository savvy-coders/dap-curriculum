{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics\n",
    "\n",
    "## Ingesting Data with Pandas\n",
    "\n",
    "![Python and Pandas!](./images/PythonPandasandDataIngestion.png)\n",
    "\n",
    "## We are going to learn about ...\n",
    "\n",
    "- Reading Data from Excel files\n",
    "- Reading data from SQL databases\n",
    "- Reading data from CSV files\n",
    "- We'll do some Data Wrangling\n",
    "- Pandas in class Practice\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data From Excel into a `DataFrame`:\n",
    "\n",
    "To read an excel file as a DataFrame, use the Python  Pandas `read_excel()` method. You can read different types of Excel file extensions:.xlsx, and .xls.\n",
    "\n",
    "You can read the first sheet, specific sheets, multiple sheets or all sheets. Pandas converts this to the DataFrame structure, which is a tabular like structure.\n",
    "\n",
    "To be able to open Excel files we need to install the module `openpyxl`\n",
    "\n",
    "    --  pip install openpyxl\n",
    "\n",
    "For our example, we will use a file from the resources folder in the curriculum. The filepath to the XLSX file is `./resources/sample_winterathletes.xlsx`. \n",
    "\n",
    "We will use the `read_excel` method as mentioned.\n",
    "\n",
    "-   The first parameter is the name of the excel file.\n",
    "-   The sheet_name parameter defines the sheet to be read from the excel file. By default, Pandas will use the first sheet (positionally), unless otherwise specified. To pass multiple sheets use: - `sheet_name=['East', 'West']`\n",
    "\n",
    "The name of the sheet we want to pull from the Excel workbook is `Athletes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import an excel sheet\n",
    "import pandas as pd\n",
    "\n",
    "athletes = pd.read_excel('./resources/sample_winterathletes.xlsx',\n",
    "                    sheet_name='Athletes')\n",
    "athletes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often you don’t want to load every column in an Excel file because there are too many columns etc. Use the `usecols=` parameter to select the columns of data you want. EX:-- `usecols=['Customer', 'Sales']`\n",
    "\n",
    "Here is a list of some important parameters that can be used with the `.read_excel()` method:-\n",
    "-   **dtype** – Dict with column name an type.\n",
    "-   **nrows** – How many rows to parse.\n",
    "-   **na_values** – Additional strings to recognize as NA/NaN. \n",
    "-   **keep_default_na** – Whether or not to include the default NaN values when parsing the data. \n",
    "-   **na_filter** – Filters missing values.\n",
    "-   **parse_dates** – Specify the column index you wanted to parse as dates\n",
    "-   **thousands** – Thousands separator for parsing string columns to numeric.\n",
    "-   ***skipfooter*** – Specify how many rows you wanted to skip from the footer.\n",
    "-   **mangle_dupe_cols** – Duplicate columns will be specified as ‘X’, ‘X.1’, …’X.N’, \n",
    "\n",
    "The `.read_excel()` method is a very complex function with many parameters that offer a wide range of useful ways to manipulate Excel input for a Pandas DataFrame. Read all about it here in this documantation -- [Syntax for `.read_excel()`.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Reading Data From `SQL`  into a `DataFrame`:\n",
    "\n",
    "Pandas has 2 **“read SQL”** methods:-  `pandas.read_sql_query()` and `pandas.read_sql()`. \n",
    "\n",
    "The `.read_sql()` method was added to make it slightly easier to work with SQL data in Pandas. It combines the functionality of two other SQL methods:\n",
    "\n",
    "-   `.read_sql_query()` -- for querying a database and reading the response into a DataFrame once a connection has been setup to the database;\n",
    "-   `.read_sql_table()` -- which allows Pandas to read a whole SQL table from a database into a DataFrame.\n",
    "\n",
    "Syntax of Pandas `.read_sql()`: -\n",
    "\n",
    "```python\n",
    "    # Syntax of read_sql()\n",
    "    pandas.read_sql(sql, con, index_col=None, coerce_float=True, \n",
    "        params=None, parse_dates=None, columns=None, chunksize=None)\n",
    "\n",
    "    # Syntax of read_sql_query()\n",
    "    pandas.read_sql_query(sql, con, index_col=None, coerce_float=True, \n",
    "        params=None, parse_dates=None, chunksize=None, dtype=None)\n",
    "\n",
    "    # Syntax of read_sql_table()\n",
    "    pandas.read_sql_table(table_name, con, schema=None, index_col=None, \n",
    "        coerce_float=True, parse_dates=None, columns=None, \n",
    "        chunksize=None)\n",
    "\n",
    "```\n",
    "\n",
    "There are drivers available for several SQL databases including SQLite, MySQL, PostgreSQL, etc.\n",
    "\n",
    "Python comes with build-in support for SQLite. However, unlike SQLite, there are no built-in Python SQL libraries for connecting to other databases. \n",
    "\n",
    "In order to connect with other databases from within a Python program, we'll need to install SQL drivers for Python, for those desired databases, and then define connectors for those drivers. A complex process.\n",
    "\n",
    "We wil use the `pandas.read_sql_query()` as mentioned, along with the `.sqlite` SQL module.\n",
    "\n",
    "The filepath is `./resources/pitchforkDatabase.sqlite`. \n",
    "\n",
    "Use the `sqlite3` library. The name of the table is `artists`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('./resources/PitchForkDatabase.sqlite')\n",
    "pfDB = pd.read_sql_query('select * from artists',con)\n",
    "pfDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Pandas handles importing SQL data way more eligantly than Python does, the `.read_sql_query()` method is still a complex function with many parameters that offer a wide range of ways to manipulate SQL input to form a Pandas DataFrame. \n",
    "\n",
    "Read all about the [Syntax and use of `.read_sql()`.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html)\n",
    "\n",
    "And here is a very simple and basic article explaining the most useful minimums for working with SQL in Pandas; simple and easy -- [pandas read_sql() method implementation with Examples](https://www.datasciencelearner.com/pandas-read_sql-implementation-examples/)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Reading data from `CSV files` into a `DataFrame`:\n",
    "\n",
    "A simple way to store big data sets is to use CSV files (comma separated files).\n",
    "\n",
    "CSV files contains plain text and is a well know format that can be read by everyone including Pandas.\n",
    "\n",
    "You can open it in Notepad but the format will be off; Use VS Code instead.\n",
    "\n",
    "To access data from the CSV file, we require a function `.read_csv()` that retrieves data in the form of the DataFrame.\n",
    "\n",
    "By default, a `CSV` is separated by commas. But one can use other separators as well. \n",
    "\n",
    "The `pandas.read_csv()` function is not limited to reading the CSV file with default separator (i.e. comma). It can be used for other separators such as `;` or `|` or `:`. \n",
    "\n",
    "To load CSV files with such separators, the `sep=` parameter is used to pass the separator used in the CSV file. Example: --\n",
    "```python\n",
    "    f = pd.read_csv(\"datafile2.csv\", sep='|')\n",
    "```\n",
    "\n",
    "For our example, we'll use a file from the resources folder in the curriculum. The filepath to the CSV file is `./resources/GREENCOMPUTERS500.csv`.\n",
    "\n",
    "Lets first look at the data by clicking this link ... [Top 500 Green Computers](./resources/GREENCOMPUTERS500.csv)\n",
    "\n",
    "Form this data we can see that we have a file with many columns.\n",
    "\n",
    "Lets see what it loos like when we import the data into a DataFrame ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a CSV file\n",
    "import pandas as pd\n",
    "\n",
    "green = pd.read_csv('./resources/GREENCOMPUTERS500.csv',index_col=0)\n",
    "green.info()\n",
    "green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all about the [Syntax and use of `.read_csv()`.](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Creating a `.csv` file from scratch\n",
    "\n",
    "We can export a Pandas DataFrame to a CSV file by using the Pandas `to_csv()` method. By default, this method exports a DataFrame to a CSV file with \"row index\" as the first column, and a comma as the delimiter. \n",
    "\n",
    "With the `sep:` we can specify a custom delimiter for the CSV output, instead of a comma.\n",
    "\n",
    "One can also save the CSV with out indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a .csv from scratch\n",
    "import pandas as pd \n",
    "\n",
    "cities = pd.DataFrame([[\"St. Louis\", \"Missouri\"], [\"Atlanta\", \"Georgia\"]], \n",
    "                        columns=[\"City\", \"State\"])\n",
    "cities\n",
    "cities.to_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sep: Specify a custom delimiter for the CSV output\n",
    "import pandas as pd \n",
    "\n",
    "cities = pd.DataFrame([[\"St. Louis\", \"Missouri\"], [\"Atlanta\", \"Georgia\"]], \n",
    "                        columns=[\"City\", \"State\"])\n",
    "\n",
    "cities.to_csv('citiesT.csv', sep='\\t')   # use tab to separate data instead of a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the newly created  .csv file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cities.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the file without indexes\n",
    "import pandas as pd \n",
    "\n",
    "cities = pd.DataFrame([[\"St. Louis\", \"Missouri\"], [\"Atlanta\", \"Georgia\"]],\n",
    "                        columns=[\"City\", \"State\"])\n",
    "\n",
    "cities.to_csv('cities.csv', index=False)\n",
    "df = pd.read_csv('cities.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all about how to use [pandas.DataFrame.to_csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Pandas Data Wrangling with a CSV file\n",
    "\n",
    "We will reuse the data file we introduced in the 1st Pandas session. For our example, we will use a file from the resources folder in the curriculum. The filepath to the CSV file is `./resources/data.csv`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and print a summary of a DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "# Print Summary of a DataFrame -- 1st 5 & last 5 lines\n",
    "print(\"Summary of our DataFrame ...\\n\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and print N number of rows from a DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "# Viewing the FIRST 10 rows\n",
    "print(\"\\nFirst 10 header rows ...\\n\\n\", df.head(10))\n",
    "\n",
    "# Viewing the LAST 12 rows\n",
    "print(\"\\nLast 12 tailing rows ...\\n\\n\", df.tail(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and print Info about a DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "# Information about the DataFrame\n",
    "print(\"\\nPrint Info on the DataFrame ...\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A closer look at the DataFrame Info …\n",
    "\n",
    "![DataFrame Info Display](./images/Pandas_DF_InfoDisplay.png)\n",
    "\n",
    "Looking at this Info reveals that there are 5 rows in the 'Calories' column without data.\n",
    "\n",
    "Nulls are bad! Nulls are the wrong result when you analyze data.\n",
    "\n",
    "### Let’s find the Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the NULLS ...\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "# This statement gives access to the WHOLE DataFrame\n",
    "print(\"\\nDF print ...\\n\", df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dropping the NULLs -- `.dropna()`**\n",
    "\n",
    "If you studied the output you should have found that the following lines contain NULLs in the 'Calories' column: 17, 27, 91, 118, 141\n",
    "\n",
    "We will use the `.dropna()` method to drop the NULLs.\n",
    "\n",
    "The `dropna()` method removes the rows that contains NULL values.\n",
    "\n",
    "The `dropna()` method returns a new DataFrame object unless the `INPLACE` parameter is set to `True`, in that case the `dropna()` method does the removing in the original DataFrame instead.\n",
    "\n",
    "> Note: In the example below, this DOES NOT change the original DataFrame BECAUSE we are using `new_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping NULS -- .dropna()\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "new_df = df.dropna()\n",
    "# check columns: 17\t27\t91\t118\t141\n",
    "print(new_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This changes the ORIGINAL DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "# check columns: 17\t27\t91\t118\t141\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about the `.dropna()` method ... [pandas.DataFrame.dropna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Replacing Nulls -- `.fillna()`**\n",
    "\n",
    "Often for data integrity sake we do not want to drop NULLs but transform and preserve them. We can replace NULLS with other values, or even calculations.\n",
    "\n",
    "The `fillna()` method replaces the NULL values with a specified value.\n",
    "\n",
    "The `fillna()` method returns a new DataFrame object unless the `inplace` parameter is set to True, in that case the `fillna()` method does the replacing in the original DataFrame instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: -- Replace **ALL** NULLs with 130\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "df.fillna(130, inplace = True)\n",
    "# check columns: 17\t27\t91\t118\t141\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Nulls in the \"Calories\" column with 130\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "df[\"Calories\"].fillna(130, inplace = True)\n",
    "# check columns: 17\t27\t91\t118\t141\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about the `.fillna()` method ... [pandas.DataFrame.fillna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Replace Nulls using Mean, Median, Mode**\n",
    "\n",
    "We can replace NULLS with specific calculations to \"fill in\" missing data with valid similar data.\n",
    "\n",
    "A common way to replace empty cells, is to calculate the Mean, Median or Mode value of the column.\n",
    "\n",
    "Pandas uses the `mean()`, `median()` and `mode()` methods to calculate the respective values for a specified column.\n",
    "\n",
    "- **Mean** = the average value\n",
    "- **Median** = the value in the middle, after you have sorted all the values ascending\n",
    "- **Mode** = the value that appears most frequently\n",
    "\n",
    "One of the key points is to decide which technique, out of the above-mentioned imputation techniques, to use for getting the most appropriate approximation for the missing values.\n",
    "\n",
    ">The goal is to find out which is a better measure of the central tendency of data and use that value for replacing missing values appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean ... 375.79\n",
      "     Duration  Pulse  Maxpulse  Calories\n",
      "0          60    110       130    409.10\n",
      "1          60    117       145    479.00\n",
      "2          60    103       135    340.00\n",
      "3          45    109       175    282.40\n",
      "4          45    117       148    406.00\n",
      "5          60    102       127    300.00\n",
      "6          60    110       136    374.00\n",
      "7          45    104       134    253.30\n",
      "8          30    109       133    195.10\n",
      "9          60     98       124    269.00\n",
      "10         60    103       147    329.30\n",
      "11         60    100       120    250.70\n",
      "12         60    106       128    345.30\n",
      "13         60    104       132    379.30\n",
      "14         60     98       123    275.00\n",
      "15         60     98       120    215.20\n",
      "16         60    100       120    300.00\n",
      "17         45     90       112    375.79\n",
      "18         60    103       123    323.00\n",
      "19         45     97       125    243.00\n",
      "20         60    108       131    364.20\n",
      "21         45    100       119    282.00\n",
      "22         60    130       101    300.00\n",
      "23         45    105       132    246.00\n",
      "24         60    102       126    334.50\n",
      "25         60    100       120    250.00\n",
      "26         60     92       118    241.00\n",
      "27         60    103       132    375.79\n",
      "28         60    100       132    280.00\n",
      "29         60    102       129    380.30\n",
      "30         60     92       115    243.00\n",
      "31         45     90       112    180.10\n",
      "32         60    101       124    299.00\n",
      "33         60     93       113    223.00\n",
      "34         60    107       136    361.00\n",
      "35         60    114       140    415.00\n",
      "36         60    102       127    300.00\n",
      "37         60    100       120    300.00\n",
      "38         60    100       120    300.00\n",
      "39         45    104       129    266.00\n",
      "40         45     90       112    180.10\n",
      "41         60     98       126    286.00\n",
      "42         60    100       122    329.40\n",
      "43         60    111       138    400.00\n",
      "44         60    111       131    397.00\n",
      "45         60     99       119    273.00\n",
      "46         60    109       153    387.60\n",
      "47         45    111       136    300.00\n",
      "48         45    108       129    298.00\n",
      "49         60    111       139    397.60\n",
      "50         60    107       136    380.20\n",
      "51         80    123       146    643.10\n",
      "52         60    106       130    263.00\n",
      "53         60    118       151    486.00\n",
      "54         30    136       175    238.00\n",
      "55         60    121       146    450.70\n",
      "56         60    118       121    413.00\n",
      "57         45    115       144    305.00\n",
      "58         20    153       172    226.40\n",
      "59         45    123       152    321.00\n",
      "60        210    108       160   1376.00\n",
      "61        160    110       137   1034.40\n",
      "62        160    109       135    853.00\n",
      "63         45    118       141    341.00\n",
      "64         20    110       130    131.40\n",
      "65        180     90       130    800.40\n",
      "66        150    105       135    873.40\n",
      "67        150    107       130    816.00\n",
      "68         20    106       136    110.40\n",
      "69        300    108       143   1500.20\n",
      "70        150     97       129   1115.00\n",
      "71         60    109       153    387.60\n",
      "72         90    100       127    700.00\n",
      "73        150     97       127    953.20\n",
      "74         45    114       146    304.00\n",
      "75         90     98       125    563.20\n",
      "76         45    105       134    251.00\n",
      "77         45    110       141    300.00\n",
      "78        120    100       130    500.40\n",
      "79        270    100       131   1729.00\n",
      "80         30    159       182    319.20\n",
      "81         45    149       169    344.00\n",
      "82         30    103       139    151.10\n",
      "83        120    100       130    500.00\n",
      "84         45    100       120    225.30\n",
      "85         30    151       170    300.00\n",
      "86         45    102       136    234.00\n",
      "87        120    100       157   1000.10\n",
      "88         45    129       103    242.00\n",
      "89         20     83       107     50.30\n",
      "90        180    101       127    600.10\n",
      "91         45    107       137    375.79\n",
      "92         30     90       107    105.30\n",
      "93         15     80       100     50.50\n",
      "94         20    150       171    127.40\n",
      "95         20    151       168    229.40\n",
      "96         30     95       128    128.20\n",
      "97         25    152       168    244.20\n",
      "98         30    109       131    188.20\n",
      "99         90     93       124    604.10\n",
      "100        20     95       112     77.70\n",
      "101        90     90       110    500.00\n",
      "102        90     90       100    500.00\n",
      "103        90     90       100    500.40\n",
      "104        30     92       108     92.70\n",
      "105        30     93       128    124.00\n",
      "106       180     90       120    800.30\n",
      "107        30     90       120     86.20\n",
      "108        90     90       120    500.30\n",
      "109       210    137       184   1860.40\n",
      "110        60    102       124    325.20\n",
      "111        45    107       124    275.00\n",
      "112        15    124       139    124.20\n",
      "113        45    100       120    225.30\n",
      "114        60    108       131    367.60\n",
      "115        60    108       151    351.70\n",
      "116        60    116       141    443.00\n",
      "117        60     97       122    277.40\n",
      "118        60    105       125    375.79\n",
      "119        60    103       124    332.70\n",
      "120        30    112       137    193.90\n",
      "121        45    100       120    100.70\n",
      "122        60    119       169    336.70\n",
      "123        60    107       127    344.90\n",
      "124        60    111       151    368.50\n",
      "125        60     98       122    271.00\n",
      "126        60     97       124    275.30\n",
      "127        60    109       127    382.00\n",
      "128        90     99       125    466.40\n",
      "129        60    114       151    384.00\n",
      "130        60    104       134    342.50\n",
      "131        60    107       138    357.50\n",
      "132        60    103       133    335.00\n",
      "133        60    106       132    327.50\n",
      "134        60    103       136    339.00\n",
      "135        20    136       156    189.00\n",
      "136        45    117       143    317.70\n",
      "137        45    115       137    318.00\n",
      "138        45    113       138    308.00\n",
      "139        20    141       162    222.40\n",
      "140        60    108       135    390.00\n",
      "141        60     97       127    375.79\n",
      "142        45    100       120    250.40\n",
      "143        45    122       149    335.40\n",
      "144        60    136       170    470.20\n",
      "145        45    106       126    270.80\n",
      "146        60    107       136    400.00\n",
      "147        60    112       146    361.90\n",
      "148        30    103       127    185.00\n",
      "149        60    110       150    409.40\n",
      "150        60    106       134    343.00\n",
      "151        60    109       129    353.20\n",
      "152        60    109       138    374.00\n",
      "153        30    150       167    275.80\n",
      "154        60    105       128    328.00\n",
      "155        60    111       151    368.50\n",
      "156        60     97       131    270.40\n",
      "157        60    100       120    270.40\n",
      "158        60    114       150    382.80\n",
      "159        30     80       120    240.90\n",
      "160        30     85       120    250.40\n",
      "161        45     90       130    260.40\n",
      "162        45     95       130    270.00\n",
      "163        45    100       140    280.90\n",
      "164        60    105       140    290.80\n",
      "165        60    110       145    300.00\n",
      "166        60    115       145    310.20\n",
      "167        75    120       150    320.40\n",
      "168        75    125       150    330.40\n"
     ]
    }
   ],
   "source": [
    "# Replace NULLS with MEAN\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "x = round((df[\"Calories\"].mean()), 2)    # the average value\n",
    "# x = round(x, 2)\n",
    "print(\"The mean ...\", x)\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)\n",
    "# check columns: 17\t27\t91\t118\t141\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the median ... 318.6\n",
      "     Duration  Pulse  Maxpulse  Calories\n",
      "0          60    110       130     409.1\n",
      "1          60    117       145     479.0\n",
      "2          60    103       135     340.0\n",
      "3          45    109       175     282.4\n",
      "4          45    117       148     406.0\n",
      "5          60    102       127     300.0\n",
      "6          60    110       136     374.0\n",
      "7          45    104       134     253.3\n",
      "8          30    109       133     195.1\n",
      "9          60     98       124     269.0\n",
      "10         60    103       147     329.3\n",
      "11         60    100       120     250.7\n",
      "12         60    106       128     345.3\n",
      "13         60    104       132     379.3\n",
      "14         60     98       123     275.0\n",
      "15         60     98       120     215.2\n",
      "16         60    100       120     300.0\n",
      "17         45     90       112     318.6\n",
      "18         60    103       123     323.0\n",
      "19         45     97       125     243.0\n",
      "20         60    108       131     364.2\n",
      "21         45    100       119     282.0\n",
      "22         60    130       101     300.0\n",
      "23         45    105       132     246.0\n",
      "24         60    102       126     334.5\n",
      "25         60    100       120     250.0\n",
      "26         60     92       118     241.0\n",
      "27         60    103       132     318.6\n",
      "28         60    100       132     280.0\n",
      "29         60    102       129     380.3\n",
      "30         60     92       115     243.0\n",
      "31         45     90       112     180.1\n",
      "32         60    101       124     299.0\n",
      "33         60     93       113     223.0\n",
      "34         60    107       136     361.0\n",
      "35         60    114       140     415.0\n",
      "36         60    102       127     300.0\n",
      "37         60    100       120     300.0\n",
      "38         60    100       120     300.0\n",
      "39         45    104       129     266.0\n",
      "40         45     90       112     180.1\n",
      "41         60     98       126     286.0\n",
      "42         60    100       122     329.4\n",
      "43         60    111       138     400.0\n",
      "44         60    111       131     397.0\n",
      "45         60     99       119     273.0\n",
      "46         60    109       153     387.6\n",
      "47         45    111       136     300.0\n",
      "48         45    108       129     298.0\n",
      "49         60    111       139     397.6\n",
      "50         60    107       136     380.2\n",
      "51         80    123       146     643.1\n",
      "52         60    106       130     263.0\n",
      "53         60    118       151     486.0\n",
      "54         30    136       175     238.0\n",
      "55         60    121       146     450.7\n",
      "56         60    118       121     413.0\n",
      "57         45    115       144     305.0\n",
      "58         20    153       172     226.4\n",
      "59         45    123       152     321.0\n",
      "60        210    108       160    1376.0\n",
      "61        160    110       137    1034.4\n",
      "62        160    109       135     853.0\n",
      "63         45    118       141     341.0\n",
      "64         20    110       130     131.4\n",
      "65        180     90       130     800.4\n",
      "66        150    105       135     873.4\n",
      "67        150    107       130     816.0\n",
      "68         20    106       136     110.4\n",
      "69        300    108       143    1500.2\n",
      "70        150     97       129    1115.0\n",
      "71         60    109       153     387.6\n",
      "72         90    100       127     700.0\n",
      "73        150     97       127     953.2\n",
      "74         45    114       146     304.0\n",
      "75         90     98       125     563.2\n",
      "76         45    105       134     251.0\n",
      "77         45    110       141     300.0\n",
      "78        120    100       130     500.4\n",
      "79        270    100       131    1729.0\n",
      "80         30    159       182     319.2\n",
      "81         45    149       169     344.0\n",
      "82         30    103       139     151.1\n",
      "83        120    100       130     500.0\n",
      "84         45    100       120     225.3\n",
      "85         30    151       170     300.0\n",
      "86         45    102       136     234.0\n",
      "87        120    100       157    1000.1\n",
      "88         45    129       103     242.0\n",
      "89         20     83       107      50.3\n",
      "90        180    101       127     600.1\n",
      "91         45    107       137     318.6\n",
      "92         30     90       107     105.3\n",
      "93         15     80       100      50.5\n",
      "94         20    150       171     127.4\n",
      "95         20    151       168     229.4\n",
      "96         30     95       128     128.2\n",
      "97         25    152       168     244.2\n",
      "98         30    109       131     188.2\n",
      "99         90     93       124     604.1\n",
      "100        20     95       112      77.7\n",
      "101        90     90       110     500.0\n",
      "102        90     90       100     500.0\n",
      "103        90     90       100     500.4\n",
      "104        30     92       108      92.7\n",
      "105        30     93       128     124.0\n",
      "106       180     90       120     800.3\n",
      "107        30     90       120      86.2\n",
      "108        90     90       120     500.3\n",
      "109       210    137       184    1860.4\n",
      "110        60    102       124     325.2\n",
      "111        45    107       124     275.0\n",
      "112        15    124       139     124.2\n",
      "113        45    100       120     225.3\n",
      "114        60    108       131     367.6\n",
      "115        60    108       151     351.7\n",
      "116        60    116       141     443.0\n",
      "117        60     97       122     277.4\n",
      "118        60    105       125     318.6\n",
      "119        60    103       124     332.7\n",
      "120        30    112       137     193.9\n",
      "121        45    100       120     100.7\n",
      "122        60    119       169     336.7\n",
      "123        60    107       127     344.9\n",
      "124        60    111       151     368.5\n",
      "125        60     98       122     271.0\n",
      "126        60     97       124     275.3\n",
      "127        60    109       127     382.0\n",
      "128        90     99       125     466.4\n",
      "129        60    114       151     384.0\n",
      "130        60    104       134     342.5\n",
      "131        60    107       138     357.5\n",
      "132        60    103       133     335.0\n",
      "133        60    106       132     327.5\n",
      "134        60    103       136     339.0\n",
      "135        20    136       156     189.0\n",
      "136        45    117       143     317.7\n",
      "137        45    115       137     318.0\n",
      "138        45    113       138     308.0\n",
      "139        20    141       162     222.4\n",
      "140        60    108       135     390.0\n",
      "141        60     97       127     318.6\n",
      "142        45    100       120     250.4\n",
      "143        45    122       149     335.4\n",
      "144        60    136       170     470.2\n",
      "145        45    106       126     270.8\n",
      "146        60    107       136     400.0\n",
      "147        60    112       146     361.9\n",
      "148        30    103       127     185.0\n",
      "149        60    110       150     409.4\n",
      "150        60    106       134     343.0\n",
      "151        60    109       129     353.2\n",
      "152        60    109       138     374.0\n",
      "153        30    150       167     275.8\n",
      "154        60    105       128     328.0\n",
      "155        60    111       151     368.5\n",
      "156        60     97       131     270.4\n",
      "157        60    100       120     270.4\n",
      "158        60    114       150     382.8\n",
      "159        30     80       120     240.9\n",
      "160        30     85       120     250.4\n",
      "161        45     90       130     260.4\n",
      "162        45     95       130     270.0\n",
      "163        45    100       140     280.9\n",
      "164        60    105       140     290.8\n",
      "165        60    110       145     300.0\n",
      "166        60    115       145     310.2\n",
      "167        75    120       150     320.4\n",
      "168        75    125       150     330.4\n"
     ]
    }
   ],
   "source": [
    "# Replace NULLS with MEDIAN\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "x = df[\"Calories\"].median()     # the value in the middle\n",
    "print(\"the median ...\", x)\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace =True)\n",
    "# check columns: 17\t27\t91\t118\t141\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mode ... 300.0\n",
      "     Duration  Pulse  Maxpulse  Calories\n",
      "0          60    110       130     409.1\n",
      "1          60    117       145     479.0\n",
      "2          60    103       135     340.0\n",
      "3          45    109       175     282.4\n",
      "4          45    117       148     406.0\n",
      "5          60    102       127     300.0\n",
      "6          60    110       136     374.0\n",
      "7          45    104       134     253.3\n",
      "8          30    109       133     195.1\n",
      "9          60     98       124     269.0\n",
      "10         60    103       147     329.3\n",
      "11         60    100       120     250.7\n",
      "12         60    106       128     345.3\n",
      "13         60    104       132     379.3\n",
      "14         60     98       123     275.0\n",
      "15         60     98       120     215.2\n",
      "16         60    100       120     300.0\n",
      "17         45     90       112     300.0\n",
      "18         60    103       123     323.0\n",
      "19         45     97       125     243.0\n",
      "20         60    108       131     364.2\n",
      "21         45    100       119     282.0\n",
      "22         60    130       101     300.0\n",
      "23         45    105       132     246.0\n",
      "24         60    102       126     334.5\n",
      "25         60    100       120     250.0\n",
      "26         60     92       118     241.0\n",
      "27         60    103       132     300.0\n",
      "28         60    100       132     280.0\n",
      "29         60    102       129     380.3\n",
      "30         60     92       115     243.0\n",
      "31         45     90       112     180.1\n",
      "32         60    101       124     299.0\n",
      "33         60     93       113     223.0\n",
      "34         60    107       136     361.0\n",
      "35         60    114       140     415.0\n",
      "36         60    102       127     300.0\n",
      "37         60    100       120     300.0\n",
      "38         60    100       120     300.0\n",
      "39         45    104       129     266.0\n",
      "40         45     90       112     180.1\n",
      "41         60     98       126     286.0\n",
      "42         60    100       122     329.4\n",
      "43         60    111       138     400.0\n",
      "44         60    111       131     397.0\n",
      "45         60     99       119     273.0\n",
      "46         60    109       153     387.6\n",
      "47         45    111       136     300.0\n",
      "48         45    108       129     298.0\n",
      "49         60    111       139     397.6\n",
      "50         60    107       136     380.2\n",
      "51         80    123       146     643.1\n",
      "52         60    106       130     263.0\n",
      "53         60    118       151     486.0\n",
      "54         30    136       175     238.0\n",
      "55         60    121       146     450.7\n",
      "56         60    118       121     413.0\n",
      "57         45    115       144     305.0\n",
      "58         20    153       172     226.4\n",
      "59         45    123       152     321.0\n",
      "60        210    108       160    1376.0\n",
      "61        160    110       137    1034.4\n",
      "62        160    109       135     853.0\n",
      "63         45    118       141     341.0\n",
      "64         20    110       130     131.4\n",
      "65        180     90       130     800.4\n",
      "66        150    105       135     873.4\n",
      "67        150    107       130     816.0\n",
      "68         20    106       136     110.4\n",
      "69        300    108       143    1500.2\n",
      "70        150     97       129    1115.0\n",
      "71         60    109       153     387.6\n",
      "72         90    100       127     700.0\n",
      "73        150     97       127     953.2\n",
      "74         45    114       146     304.0\n",
      "75         90     98       125     563.2\n",
      "76         45    105       134     251.0\n",
      "77         45    110       141     300.0\n",
      "78        120    100       130     500.4\n",
      "79        270    100       131    1729.0\n",
      "80         30    159       182     319.2\n",
      "81         45    149       169     344.0\n",
      "82         30    103       139     151.1\n",
      "83        120    100       130     500.0\n",
      "84         45    100       120     225.3\n",
      "85         30    151       170     300.0\n",
      "86         45    102       136     234.0\n",
      "87        120    100       157    1000.1\n",
      "88         45    129       103     242.0\n",
      "89         20     83       107      50.3\n",
      "90        180    101       127     600.1\n",
      "91         45    107       137     300.0\n",
      "92         30     90       107     105.3\n",
      "93         15     80       100      50.5\n",
      "94         20    150       171     127.4\n",
      "95         20    151       168     229.4\n",
      "96         30     95       128     128.2\n",
      "97         25    152       168     244.2\n",
      "98         30    109       131     188.2\n",
      "99         90     93       124     604.1\n",
      "100        20     95       112      77.7\n",
      "101        90     90       110     500.0\n",
      "102        90     90       100     500.0\n",
      "103        90     90       100     500.4\n",
      "104        30     92       108      92.7\n",
      "105        30     93       128     124.0\n",
      "106       180     90       120     800.3\n",
      "107        30     90       120      86.2\n",
      "108        90     90       120     500.3\n",
      "109       210    137       184    1860.4\n",
      "110        60    102       124     325.2\n",
      "111        45    107       124     275.0\n",
      "112        15    124       139     124.2\n",
      "113        45    100       120     225.3\n",
      "114        60    108       131     367.6\n",
      "115        60    108       151     351.7\n",
      "116        60    116       141     443.0\n",
      "117        60     97       122     277.4\n",
      "118        60    105       125     300.0\n",
      "119        60    103       124     332.7\n",
      "120        30    112       137     193.9\n",
      "121        45    100       120     100.7\n",
      "122        60    119       169     336.7\n",
      "123        60    107       127     344.9\n",
      "124        60    111       151     368.5\n",
      "125        60     98       122     271.0\n",
      "126        60     97       124     275.3\n",
      "127        60    109       127     382.0\n",
      "128        90     99       125     466.4\n",
      "129        60    114       151     384.0\n",
      "130        60    104       134     342.5\n",
      "131        60    107       138     357.5\n",
      "132        60    103       133     335.0\n",
      "133        60    106       132     327.5\n",
      "134        60    103       136     339.0\n",
      "135        20    136       156     189.0\n",
      "136        45    117       143     317.7\n",
      "137        45    115       137     318.0\n",
      "138        45    113       138     308.0\n",
      "139        20    141       162     222.4\n",
      "140        60    108       135     390.0\n",
      "141        60     97       127     300.0\n",
      "142        45    100       120     250.4\n",
      "143        45    122       149     335.4\n",
      "144        60    136       170     470.2\n",
      "145        45    106       126     270.8\n",
      "146        60    107       136     400.0\n",
      "147        60    112       146     361.9\n",
      "148        30    103       127     185.0\n",
      "149        60    110       150     409.4\n",
      "150        60    106       134     343.0\n",
      "151        60    109       129     353.2\n",
      "152        60    109       138     374.0\n",
      "153        30    150       167     275.8\n",
      "154        60    105       128     328.0\n",
      "155        60    111       151     368.5\n",
      "156        60     97       131     270.4\n",
      "157        60    100       120     270.4\n",
      "158        60    114       150     382.8\n",
      "159        30     80       120     240.9\n",
      "160        30     85       120     250.4\n",
      "161        45     90       130     260.4\n",
      "162        45     95       130     270.0\n",
      "163        45    100       140     280.9\n",
      "164        60    105       140     290.8\n",
      "165        60    110       145     300.0\n",
      "166        60    115       145     310.2\n",
      "167        75    120       150     320.4\n",
      "168        75    125       150     330.4\n"
     ]
    }
   ],
   "source": [
    "# Replace NULLS with MODE\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "x = df[\"Calories\"].mode()[0]    # value that appears most\n",
    "print(\"the mode ...\", x)\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)\n",
    "# check columns: 17\t27\t91\t118\t141\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### **Replacing Incorrect data in DataFrames**\n",
    "\n",
    "So, you want to replace values in your DataFrame with something else? No problem. That is where Pandas Replace comes in.\n",
    "\n",
    "Pandas `DataFrame.replace()` is a small but powerful function that will replace (or swap) values in your DataFrame with another value. It can replace strings, regex, lists, dictionaries, series, numbers, etc. from a Dataframe. \n",
    "\n",
    "Every instance of the provided value is replaced after a thorough search of the full DataFrame, depending on the parameters used...\n",
    "\n",
    "    Syntax:     df.replace(to_replace = 'what you want to replace',\n",
    "                            value = 'what you want to replace it with')\n",
    "\n",
    "What starts as a simple function, can quickly be expanded for most of your scenarios.\n",
    "\n",
    "Pandas `.replace()` can quickly get nuanced as you dig deeper. Here are the most common ways to use pandas replace:\n",
    "\n",
    "**Pandas Replace**\n",
    "\n",
    "| Code | Plain Language |\n",
    "|----|----|\n",
    "| df.replace(0, 5) | Replace all of the 0s in your DataFrame with 5s |\n",
    "| df.replace([0, 1, 2, 3], 4) | Replace all the 0s, 1s, 2s, 3s in your DataFrame with 4s |\n",
    "| df.replace([0, 1, 2, 3], [4, 3, 2, 1]) | Replace all the 0s with 4s, 1s with 3s, 2s with 2s, and 3s with 1s. Note: if you pass two lists they both much be the same length |\n",
    "| df.replace({0: 10, 1: 100}) | Using a dict – Replace 0s with 10s, and 1s with 100s. |\n",
    "| df.replace({'A': 0, 'B': 5}, 100) | Replace 0’s in column “A” with 100, and replace 5s in column “B” with 100 |\n",
    "| df.replace({'C': {1: 100, 3: 300}}) | Using a dict – Within column “C” replace 1s with 100 and 3s with 300 |\n",
    "| df.replace(to_replace=r'^ba.$', value='new', regex=True) | Replace anything that matched the regex ‘^ba.$’ with “new” |\n",
    "\n",
    "<br>\n",
    "\n",
    "**Replace Parameters**\n",
    "\n",
    "- **to_replace**: - The values, list of values, or values which match regex, you want to replace. If using a dict, you can also include the values you would like to do the replacing\n",
    "- **value**: - Values that will do the replacing. **Note**: This can also be none if you have a `dict` in your `to_replace` parameter\n",
    "- **inplace (Default: False)**: - If true, it write over your current DataFrame. If false, then your DataFrame will be returned to you.\n",
    "- **limit**: - The max size you could like to forward or back fill. Example: The number of rows to fill before and after the current point\n",
    "- **regex**: - If you want `to_replace` to read your inputs as regex or not\n",
    "- **method**: - The fill method to use when `to_replace` is either a scalar, list, or tuple. Value must be None\n",
    "- **pad/ffill**: – Take the value that is in the back of what your replacing, and fill it going forward\n",
    "- **bfill**: – Take the value that is in the front of your value to be replaced, and fill it going backward\n",
    "\n",
    ">`(to_replace)` can be a list consisting of str, regex or numeric objects. If both `to_replace` and `value` are lists, they must be the same length.\n",
    "\n",
    "For full detail on how to use all these options please refer to the documentation on [pandas.DataFrame.replace](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)\n",
    "\n",
    "\n",
    "**So. let's replace some values ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'X': [1, 2, 3, 4, 5],\n",
    "                    'Y': [5, 6, 7, 8, 9],\n",
    "                    'Z': ['z', 'y', 'x', 'w', 'v']})\n",
    "\n",
    "# Replace all 2s with 20s\n",
    "df1 = df.replace(to_replace=2, value=20)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'X': [1, 2, 3, 4, 5],\n",
    "                    'Y': [5, 6, 7, 8, 9],\n",
    "                    'Z': ['z', 'y', 'x', 'w', 'v']})\n",
    "\n",
    "# replace all 1s, 3s, and 5s with 20\n",
    "df2 = df.replace(to_replace=[1,3,5], value=20)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'X': [1, 2, 3, 4, 5],\n",
    "                    'Y': [5, 6, 7, 8, 9],\n",
    "                    'Z': ['z', 'y', 'x', 'w', 'v']})\n",
    "\n",
    "# here 1s get replaced with 10s, 3s with 30s and 5s with 50s\n",
    "df3 = df.replace(to_replace=[1,3,5], value=[10,30,50])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'X': [1, 2, 3, 4, 5],\n",
    "                    'Y': [5, 6, 7, 8, 9],\n",
    "                    'Z': ['z', 'y', 'x', 'w', 'v']})\n",
    "\n",
    "# replacing 1s with 10s, 'z's with 'zz's, and 'v's with 'vvv's\n",
    "df4 = df.replace(to_replace={1: 10, 'z':'zz', 'v':'vvv'})\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### **Fixing Dates in DataFrames**\n",
    "\n",
    "In most of the big data scenarios , there will be a requirement to fix date issues. It could be necessary to flip a date format, change date formats, or to correct them based on certain region, flag incorrect dates, and fix them appropriately.\n",
    "\n",
    "For the next examples we will use a much smaller dataset from the resources folder.\n",
    "\n",
    "The filepath to the CSV file is `./resources/data1.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Dates in DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./resources/data1.csv\")\n",
    "print(df.to_string())\n",
    "\n",
    "# drop NULL dates inplace\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.dropna(subset=['Date'], inplace = True)\n",
    "\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    " \n",
    " #### **Fixing wrong info in a specific LOCATION**\n",
    "\n",
    "Pandas provides two ways, `loc()` and `at()`, to access or change a single value of a DataFrame.\n",
    "\n",
    "- Use `at()` if you only need to get or set a single value in a DataFrame or Series.\n",
    "- On the other hand `loc()`can be used to access a single value but also to access a group of rows and columns by a label or labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing wrong info in a specific LOCATION\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./resources/data1.csv\")\n",
    "print(df.to_string())\n",
    "\n",
    "# Change line 9 \"Duration\" from 60 to be 45\n",
    "df.loc[9, 'Duration'] = 45\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    " \n",
    " #### **Fixing wrong info in LARGE sets by looping**\n",
    "\n",
    "\"Wrong data\" does not have to be \"empty cells\" or \"wrong format\", it can just be wrong, like if someone registered \"199\" instead of \"1.99\".\n",
    "\n",
    "Loop through all values in the \"Duration\" column; If the value is higher than 120, set it to 120:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing wrong info in LARGE sets by looping\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "\n",
    "for x in df.index:\n",
    "    if df.loc[x, \"Duration\"] > 120:\n",
    "        df.loc[x, \"Duration\"] = 120\n",
    "\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### **Dropping / Deleting rows from a DataFrame**\n",
    "\n",
    "Another way of handling wrong data is to remove the rows that contains wrong data.\n",
    "\n",
    "This way you do not have to find out what to replace them with, and there is a good chance you do not need them to do your analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows in LARGE sets\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./resources/data.csv\")\n",
    "print(df.info())\n",
    "\n",
    "for x in df.index:\n",
    "    if df.loc[x, \"Duration\"] > 120:\n",
    "        df.drop(x, inplace = True)\n",
    "\n",
    "print(df.info())\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- \n",
    " \n",
    " #### **Discovering Duplicates**\n",
    "\n",
    "Duplicate rows are rows that have been registered more than one time.\n",
    "To discover duplicates, we can use the `duplicated()` method.\n",
    "\n",
    "The `duplicated()` method returns a Boolean values for each row; in other words, it returns `True` for every row that is a duplicate, otherwise `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all Duplicates\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./resources/data1.csv\")\n",
    "print(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Removing Duplicates**\n",
    "\n",
    "To remove duplicates, use the `drop_duplicates()` method.\n",
    "\n",
    ">Remember: The `inplace = True` will make sure that the method does NOT return a new DataFrame, but it will remove all duplicates from the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all Duplicates\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./resources/data1.csv\")\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "print(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### More practice with CSV files - Titanic\n",
    "\n",
    "First, we need to gather our data.\n",
    "\n",
    "We can either use the data from our resources directory, or we can import our data from the WEB.\n",
    "\n",
    "The filepath to the CSV file in the curriculum resources folder is [\"./resources/titanic.csv\"](./resources/titanic.csv).\n",
    "\n",
    "Else, the URL to the data file on the WEB is ... https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
    "\n",
    "You can download that file to your machine, or we will pull that file directly in our code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to gather our data\n",
    "import pandas as pd\n",
    "\n",
    "titanic_data  = pd.read_csv(\"./resources/titanic.csv\")\n",
    "\n",
    "print(titanic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wanted to use the data straight from the web\n",
    "import pandas as pd \n",
    "\n",
    "titanic_data = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "\n",
    "print(titanic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you copied the file to your desktop\n",
    "import pandas as pd\n",
    "\n",
    "titanic_data = pd.read_csv(r\"C:\\Users\\User\\Desktop\\DAP2022\\titanic.csv\")\n",
    "\n",
    "print(titanic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing Data Headers\n",
    "import pandas as pd \n",
    "\n",
    "col_names = [\"Id\", \"Survived\", \n",
    "                \"Passenger Class\", \"Full Name\", \n",
    "                \"Gender\", \"Age\", \"SibSp\", \"Parch\", \n",
    "                \"Ticket Number\", \"Price\", \"Cabin\", \"Station\"] \n",
    "\n",
    "titanic_data = pd.read_csv(r\"./resources/titanic.csv\", names = col_names) \n",
    "print(titanic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping Rows\n",
    "import pandas as pd \n",
    "\n",
    "col_names = [\"Id\", \"Survived\", \n",
    "                \"Passenger Class\", \"Full Name\", \n",
    "                \"Gender\", \"Age\", \"SibSp\", \"Parch\", \n",
    "                \"Ticket Number\", \"Price\", \"Cabin\", \"Station\"] \n",
    "\n",
    "titanic_data = pd.read_csv(r\"./resources/titanic.csv\", names = col_names, skiprows=[0]) \n",
    "print(titanic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to a new .csv file\n",
    "import pandas as pd \n",
    "\n",
    "col_names = [\"Id\", \"Survived\", \n",
    "                \"Passenger Class\", \"Full Name\", \n",
    "                \"Gender\", \"Age\", \"SibSp\", \"Parch\", \n",
    "                \"Ticket Number\", \"Price\", \"Cabin\", \"Station\"] \n",
    "\n",
    "titanic_data = pd.read_csv(r\"./resources/titanic.csv\", names = col_names, skiprows=[0]) \n",
    "\n",
    "titanic_data.to_csv('use_titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the newly created  .csv file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('use_titanic.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Plotting & Practice with Pandas, Matplotlib and `.csv` files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting directly from a .csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./resources/data1.csv\")\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatter plot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./resources/data1.csv\")\n",
    "\n",
    "df.plot(kind = \"scatter\", x = \"Duration\", y = \"Calories\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Histogram plot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./resources/data1.csv\")\n",
    "\n",
    "df[\"Duration\"].plot(kind ='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue working with Matplotlib in the next session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
