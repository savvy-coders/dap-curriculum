{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics\n",
    "\n",
    "![Python and Pandas!](./images/PythonAndPandas.png)\n",
    "\n",
    "## We are going to learn about ...\n",
    "\n",
    "- What is Pandas\n",
    "- Pandas & NumPy\n",
    "- What Pandas can do\n",
    "- Pandas DataFrames & Series\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas\n",
    "\n",
    "- An open-source Python package that is most widely used for data science/data analysis and machine learning tasks. \n",
    "- Built on top of NumPy which provides support for multi-dimensional arrays.\n",
    "- References both “Panel Data” and “Python Data Analysis”\n",
    "- The name Pandas is derived from the word \"Panel Data\"\n",
    "- Created by Wes McKinney in 2008\n",
    "\n",
    "## Pandas & NumPy\n",
    "\n",
    "- NumPy is a library that adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "- Pandas is a high-level data manipulation tool that is built on the NumPy package\n",
    "- Pandas offers an in-memory 2d table object called a DataFrame\n",
    "- A DataFrame is structured like a table or spreadsheet -- with rows and columns\n",
    "- There are a few functions that exist in NumPy that we use specifically on Pandas DataFrames\n",
    "- Just as the \"ndarray\" is the foundation of NumPy, the \"Series\" is the core object of Pandas\n",
    "- NumPy consumes less memory than Pandas, and is faster than Pandas\n",
    "- These two libraries are the best libraries for data science applications\n",
    "- Pandas mainly works with tabular data, whereas NumPy works with numerical data\n",
    "\n",
    "## Pandas & Jupyter Notebooks\n",
    "\n",
    "Jupyter Notebooks offer a good environment for using pandas to do data exploration and modeling, but pandas can also be used in text editors just as easily.\n",
    "\n",
    "Jupyter Notebooks give us the ability to execute code in a particular cell as opposed to running the entire file. This saves a lot of time when working with large datasets and complex transformations. \n",
    "\n",
    "Notebooks also provide an easy way to visualize pandas’ DataFrames and plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can Pandas do?\n",
    "\n",
    "Pandas can perform five significant steps required for processing and analysis of data, irrespective of the origin of the data, -- load, manipulate, prepare, model, and analyze.\n",
    "\n",
    "What’s cool about Pandas is that it takes data (like a CSV or TSV file, or a SQL database) and creates a Python object with rows and columns called a 'data frame' that looks very similar to table in statistical software (think Excel).\n",
    "\n",
    "In fact, with Pandas, you can do everything that makes world-leading data scientists vote Pandas as the best data analysis and manipulation Python tool available.\n",
    "\n",
    "### Pandas can do ...\n",
    "\n",
    "|    |    |\n",
    "|----|----|\n",
    "| Data Cleansing | Data fill |\n",
    "| Data normalization | Merges and joins |\n",
    "| Data visualization | Statistical analysis |\n",
    "| Data inspection | Loading and saving data |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Using Pandas\n",
    "\n",
    "**Remember: Pandas is a Module.**\n",
    "\n",
    "You have to install it first, and NumPy is required:\n",
    "\n",
    "```python\n",
    "    pip install pandas\n",
    "```\n",
    "\n",
    "Then you have to import it at the beginning of every code file to use it:\n",
    "\n",
    "```python\n",
    "    import pandas as pd\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames & Series\n",
    "\n",
    "A Series is essentially a column, and a DataFrame is a multi-dimensional table made up of a collection of Series.\n",
    "\n",
    "DataFrames and Series are quite similar in that many operations that you can do with one you can do with the other, such as filling in null values and calculating the mean\n",
    "\n",
    "![Pandas Series and DataFrames](./images/Pandas_series-and-dataframe.png)\n",
    "\n",
    "### Pandas Series\n",
    "\n",
    "- A Pandas Series is like a column in a table\n",
    "- It is a one-dimensional array holding data of any type\n",
    "- If nothing else is specified, the values of the series are labeled with their index numbers -- first value has index 0, second value has index 1 etc.\n",
    "- These labels can be used to access specified values in the series\n",
    "- With the index argument, you can name your own labels for the indexes of your series\n",
    "- When you have created labels, you can access an item by referring to the label\n",
    "- You can also use a key/value object, like a dictionary, when creating a Series\n",
    "- You can create a DataFrame from two Series\n",
    "\n",
    "### Pandas DataFrames\n",
    "\n",
    "- A Pandas DataFrame is a 2-D data structure, like a 2 dimensional array, or a table with rows and columns\n",
    "- Pandas use the loc attribute to return one or more specified row(s)\n",
    "- With the index argument, you can name your own indexes\n",
    "- Use the named index in the loc attribute to return the specified row(s)\n",
    "- If your data sets are stored in a file, Pandas can load them into a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Working with Series...\n",
    "\n",
    "In pandas, Series is a one-dimensional, labeled array, capable of holding any data type(integers, strings, floating-point numbers, Python objects, etc.). \n",
    "\n",
    "Series store data in sequential order. It is one-column information similar to a columns in an excel sheet/SQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series Example\n",
    "\n",
    "Create a new Python file -- make sure it has a .py extension\n",
    "\n",
    "Type this code into your Python file, open the terminal, and run it...\n",
    "\n",
    "```python\n",
    "    import pandas as pd\n",
    "    age = [20, 40, 60]\n",
    "    years = pd.Series(age)\n",
    "    print(years)\n",
    "\n",
    "```\n",
    "> To run it in your terminal type ...\n",
    "\n",
    "```bash\n",
    "    python filename.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "age = [20, 40, 60]\n",
    "years = pd.Series(age)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the location of a row in a series ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a row using the index value\n",
    "import pandas as pd\n",
    "age = [20, 40, 60]\n",
    "years = pd.Series(age)\n",
    "\n",
    "print(age[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Combine Two Series into a Pandas DataFrame\n",
    "\n",
    "Using the Pandas `.concat()`, `Series.append()`, `Pandas.merge()`, and `DataFrame.join()` methods you can combine / merge two or more series into a DataFrame.\n",
    "\n",
    "#### 1.) Combine Two Series Using the Pandas `.concat()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can combine multiple series along a particular axis (column-wise or row-wise)\n",
    "import pandas as pd\n",
    "\n",
    "# Create pandas Series\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"])\n",
    "fees = pd.Series([22000,25000,23000])\n",
    "discount  = pd.Series([1000,2300,1000])\n",
    "\n",
    "# Combine two series\n",
    "df=pd.concat([courses,fees],axis=1)\n",
    "print(\"Concat 2 lists ...\\n\", df)\n",
    "\n",
    "# Combine multiple series\n",
    "df=pd.concat([courses,fees,discount],axis=1)\n",
    "print(\"\\nConcat 3 lists ...\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that if a Series doesn’t contains names, and names are not provided for columns while merging, default numbers are assigned to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series by assigning names to each\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "discount  = pd.Series([1000,2300,1000],name='discount')\n",
    "\n",
    "df=pd.concat([courses,fees,discount],axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you add custom indexes to a Series, the `combine()` method carries the same indexes to the created DataFrame. \n",
    "\n",
    "Now let’s see how to assign indexes to a Series and provide custom column names to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series with assigned indexes and provide custom column names to each\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "discount  = pd.Series([1000,2300,1000],name='discount')\n",
    "\n",
    "# Assign Index to Series\n",
    "index_labels=['r1','r2','r3']\n",
    "courses.index = index_labels\n",
    "fees.index = index_labels\n",
    "discount.index = index_labels\n",
    "\n",
    "# Concat Series by Changing Names\n",
    "df=pd.concat({'Courses': courses,\n",
    "                'Course_Fee': fees,\n",
    "                'Course_Discount': discount},axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how to rest the indexes using the `reset_index()` method. \n",
    "\n",
    "This moves the current index as a column and adds a new index to a combined DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series with assigned indexes and provide custom column names to each\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "discount  = pd.Series([1000,2300,1000],name='discount')\n",
    "\n",
    "# Assign Index to Series\n",
    "index_labels=['r1','r2','r3']\n",
    "courses.index = index_labels\n",
    "fees.index = index_labels\n",
    "discount.index = index_labels\n",
    "\n",
    "# Concat Series by Changing Names\n",
    "df=pd.concat({'Courses': courses,\n",
    "                'Course_Fee': fees,\n",
    "                'Course_Discount': discount},axis=1)\n",
    "\n",
    "#change the index to a column & create new index\n",
    "df = df.reset_index()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.) Combine Two Series Using `pandas.merge()`\n",
    "\n",
    "The Pandas `merge()` method is used to combine complex column-wise combinations of DataFrame similar SQL-like joins. \n",
    "\n",
    "Pandas `merge()` can be used for all database join operations between DataFrame or named series objects. You have to pass the extra parameter “name” to the series in this case.\n",
    "\n",
    "For instance, `pd.merge(S1, S2, right_index=True, left_index=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series by assigning names\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "\n",
    "# using pandas series merge()\n",
    "df = pd.merge(courses, fees, right_index = True,\n",
    "                left_index = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.) Combine Two Series Using `DataFrame.join()`\n",
    "\n",
    "You can also use `DataFrame.join()` to join two series. \n",
    "\n",
    "In order to use the `DataFrame.join()`, you need to have a DataFrame object. One way to get is by creating a DataFrame from some Series, and then use the DataFrame to combine with another Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series by assigning names\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "\n",
    "# Using DataFrame.join()\n",
    "df=pd.DataFrame(courses).join(fees)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.) Using `Series.append()` to Combine Two Series\n",
    "\n",
    "You can use `pandas.DataFrame(Series.append(Series,ignore_index=True))` to create a DataFrame by appending series to another series. \n",
    "\n",
    "Note that in this example it doesn’t create multiple columns instead it just appends as multiple row’s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Series.append()\n",
    "courses_am=pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"])\n",
    "courses_pm=pd.Series([\"Pandas\",\"Python\",\"Scala\"])\n",
    "\n",
    "df = pd.DataFrame(courses_am.append(courses_pm,\n",
    "                                    ignore_index = True),\n",
    "                    columns=['all_courses'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Working with Dataframes ...\n",
    "\n",
    "There are many ways to create a DataFrame from scratch, but a great option is to just use a simple `dict`, and then pass it to the pandas DataFrame constructor.\n",
    "\n",
    "Each (key, value) item in the dictionary will correspond to a column in the resulting DataFrame.\n",
    "\n",
    "The Index of this DataFrame is given by default on creation, but we could also create our own when we initialize the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# create a dictionary\n",
    "data = {\n",
    "    'apples': [3, 2, 0, 1], \n",
    "    'oranges': [0, 3, 7, 2]\n",
    "}\n",
    "\n",
    "# pass the dict to the Pandas DataFrame constructor\n",
    "purchases = pd.DataFrame(data)\n",
    "print(\"Purchases DataFrame ...\\n\", purchases)\n",
    "\n",
    "# we could create our own indexes when we initialize the DataFrame\n",
    "purchases = pd.DataFrame(data, index=['June', 'Robert', 'Lily', 'David'])\n",
    "\n",
    "print(\"\\nPurchases w/ customer indexes ...\\n\", purchases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Example\n",
    "\n",
    "Create a new Jupyter Notebook file -- make sure it has a .ipynb extension. You could run Jupyter inside VS Code or in the Jupyter Notebook console in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the location of a row in a dataframe...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the location of a row\n",
    "import pandas as pd\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report)\n",
    "print(results.loc[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: This example above returns a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the Location of More than 1 row\n",
    "import pandas as pd\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report)\n",
    "print(results.loc[[2, 3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: When using `[[ ]]` above, the result is a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming the rows / indexes\n",
    "\n",
    "import pandas as pd\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report, index = [\"week1\", \"week2\", \"week3\", \"week4\", \"week5\"])\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating a specific row using the named indexes\n",
    "\n",
    "import pandas as pd\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report, index = [\"week1\", \"week2\", \"week3\", \"week4\", \"week5\"])\n",
    "print(results.loc[\"week3\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
